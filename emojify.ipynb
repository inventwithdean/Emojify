{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from emo_utils import *\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again, üòû\n",
      "I am proud of your achievements, üòÑ\n",
      "It is the worst day in my life, üòû\n",
      "Miss you so much, ‚ù§Ô∏è\n",
      "food is life, üç¥\n",
      "I love you mum, ‚ù§Ô∏è\n",
      "Stop saying bullshit, üòû\n",
      "congratulations on your acceptance, üòÑ\n",
      "The assignment is too long , üòû\n",
      "I want to go play, ‚öæ\n"
     ]
    }
   ],
   "source": [
    "for idx in range(10):\n",
    "    print(f\"{X_train[idx]}, {label_to_emoji(Y_train[idx])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C=5)\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 'I missed you' has label index 0, which is emoji ‚ù§Ô∏è\n",
      "Label index 0 in one-hot encoding format is [1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "idx = 50\n",
    "print(f\"Sentence '{X_train[50]}' has label index {Y_train[idx]}, which is emoji {label_to_emoji(Y_train[idx])}\", )\n",
    "print(f\"Label index {Y_train[idx]} in one-hot encoding format is {Y_oh_train[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cucumber is at 113317th index\n",
      "potatos is at 289846th index\n"
     ]
    }
   ],
   "source": [
    "word = \"cucumber\"\n",
    "idx = 289846\n",
    "print(f\"{word} is at {word_to_index[word]}th index\")\n",
    "print(f\"{index_to_word[idx]} is at {idx}th index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emojify V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
    "    and averages its value into a single vector encoding the meaning of the sentence.\n",
    "    \n",
    "    Arguments:\n",
    "    sentence -- string, one training example from X\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    \n",
    "    Returns:\n",
    "    avg -- average vector encoding information about the sentence, numpy-array of shape (50,)\n",
    "    \"\"\"\n",
    "    words = sentence.lower().split()\n",
    "    m = 0\n",
    "    any_word = list(word_to_vec_map.keys())[0]\n",
    "    avg = np.zeros((word_to_vec_map[any_word].shape))\n",
    "    for word in words:\n",
    "        if word in list(word_to_vec_map.keys()):\n",
    "            avg += word_to_vec_map[word]\n",
    "            m += 1\n",
    "    if m == 0:\n",
    "        return avg\n",
    "    avg /= m\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ z^{(i)} = W . avg^{(i)} + b$$\n",
    "\n",
    "$$ a^{(i)} = softmax(z^{(i)})$$\n",
    "\n",
    "$$ \\mathcal{L}^{(i)} = - \\sum_{k = 0}^{n_y - 1} Y_{oh,k}^{(i)} * log(a^{(i)}_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 200):\n",
    "    \"\"\"\n",
    "    Model to train word vector representations in numpy.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, numpy array of sentences as strings, of shape (m, 1)\n",
    "    Y -- labels, numpy array of integers between 0 and 7, numpy-array of shape (m, 1)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    learning_rate -- learning_rate for the stochastic gradient descent algorithm\n",
    "    num_iterations -- number of iterations\n",
    "    \n",
    "    Returns:\n",
    "    pred -- vector of predictions, numpy-array of shape (m, 1)\n",
    "    W -- weight matrix of the softmax layer, of shape (n_y, n_h)\n",
    "    b -- bias of the softmax layer, of shape (n_y,)\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    any_word = list(word_to_vec_map.keys())[0]\n",
    "    n_h = word_to_vec_map[any_word].shape[0]\n",
    "    n_y = len(np.unique(Y))\n",
    "    W = np.zeros((n_y, n_h))\n",
    "    b = np.zeros((n_y,))\n",
    "    Y_oh = convert_to_one_hot(Y, C=n_y)\n",
    "\n",
    "    for epoch in range(num_iterations):\n",
    "        for s in range(m):\n",
    "            avg = sentence_to_avg(X[s], word_to_vec_map)\n",
    "            z = np.matmul(W, avg) + b\n",
    "            a = softmax(z)\n",
    "            cost = -np.sum(Y_oh[s]*np.log(a))\n",
    "            # Compute gradients \n",
    "            dz = a - Y_oh[s]\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "\n",
    "            # Update parameters with Stochastic Gradient Descent\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch: \" + str(epoch) + \" --- cost = \" + str(cost))\n",
    "            pred = predict(X, Y, W, b, word_to_vec_map) #predict is defined in emo_utils.py\n",
    "\n",
    "    return pred, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = 1.651687023969562\n",
      "Accuracy: 0.3712121212121212\n"
     ]
    }
   ],
   "source": [
    "pred, W, b = model(X_train, Y_train, word_to_vec_map, num_iterations=10) #Train it to 200 epochs for good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.7575757575757576\n",
      "Test set:\n",
      "Accuracy: 0.6964285714285714\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(sentence, W=W, b=b, word_to_vec_map=word_to_vec_map):\n",
    "    \"\"\"\n",
    "    Given X (sentences) and Y (emoji indices), predict emojis and compute the accuracy of your model over the given set.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data containing sentences, numpy array of shape (m, None)\n",
    "    Y -- labels, containing index of the label emoji, numpy array of shape (m, 1)\n",
    "    \n",
    "    Returns:\n",
    "    pred -- numpy array of shape (m, 1) with your predictions\n",
    "    \"\"\"\n",
    "    avg = sentence_to_avg(sentence, word_to_vec_map)\n",
    "    z = np.matmul(W, avg) + b\n",
    "    pred = np.argmax(softmax(z))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚ù§Ô∏è'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_emoji(int(predict_single(\"I love you\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "\n",
      "i adore you ‚ù§Ô∏è\n",
      "i love you ‚ù§Ô∏è\n",
      "funny lol üòÑ\n",
      "lets play with a ball ‚öæ\n",
      "food is ready üç¥\n",
      "not feeling happy üòû\n"
     ]
    }
   ],
   "source": [
    "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "\n",
    "pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
    "print_predictions(X_my_sentences, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emojify V2 - Using LSTM in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Input, Embedding\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/embedding1.png\" style=\"width:700px;height:250px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \"\"\"\n",
    "    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n",
    "    The output shape should be such that it can be given to `Embedding()` (See Figure above). \n",
    "    \n",
    "    Arguments:\n",
    "    X -- array of sentences (strings), of shape (m, 1)\n",
    "    word_to_index -- a dictionary containing the each word mapped to its index\n",
    "    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n",
    "    \n",
    "    Returns:\n",
    "    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    for i in range(m):\n",
    "        sentence = X[i].lower().split()\n",
    "        for j, word in enumerate(sentence):\n",
    "            if word in list(word_to_index.keys()):\n",
    "                X_indices[i][j] = word_to_index[word]\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
      "X1_indices =\n",
      " [[155345. 225122.      0.      0.      0.]\n",
      " [220930. 286375.  69714.      0.      0.]\n",
      " [151204. 192973. 302254. 151349. 394475.]]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
    "X1_indices = sentences_to_indices(X1, word_to_index, max_len=5)\n",
    "print(\"X1 =\", X1)\n",
    "print(\"X1_indices =\\n\", X1_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrained Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
    "    \n",
    "    Arguments:\n",
    "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "\n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    any_word = list(word_to_vec_map.keys())[0]\n",
    "    emb_dim = word_to_vec_map[any_word].shape[0]\n",
    "\n",
    "    emb_matrix = np.zeros((vocab_size, emb_dim))\n",
    "    for word, vec in word_to_vec_map.items():\n",
    "        emb_matrix[word_to_index[word]] = vec\n",
    "    \n",
    "    embedding_layer = Embedding(vocab_size, emb_dim, trainable=False)\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights[0][1][1] = 0.0\n",
      "Input_dim 400001\n",
      "Output_dim 50\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "print(\"weights[0][1][1] =\", embedding_layer.get_weights()[0][0][1])\n",
    "print(\"Input_dim\", embedding_layer.input_dim)\n",
    "print(\"Output_dim\",embedding_layer.output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Emojify_V2(input_shape, word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Function creating the Emojify-v2 model's graph.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape, dtype='int32')\n",
    "    X = pretrained_embedding_layer(word_to_vec_map, word_to_index)(inputs)\n",
    "    X = LSTM(units=128, return_sequences=True)(X)\n",
    "    X = Dropout(rate=0.5)(X)\n",
    "    X = LSTM(units=128, return_sequences=False)(X)\n",
    "    X = Dropout(rate=0.5)(X)\n",
    "    X = Dense(units=5, activation='softmax')(X)\n",
    "    return Model(inputs=inputs, outputs=X, name='SPN_Emojify')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SPN_Emojify\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 10, 50)            20000050  \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 10, 128)           91648     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Emojify_V2((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 4s 8ms/step - loss: 1.6131 - accuracy: 0.1591\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.5029 - accuracy: 0.3485\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.4635 - accuracy: 0.4167\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.3928 - accuracy: 0.4621\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.2916 - accuracy: 0.4848\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 1.2102 - accuracy: 0.5379\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.0748 - accuracy: 0.5833\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.9823 - accuracy: 0.6364\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.8451 - accuracy: 0.6970\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7064 - accuracy: 0.7424\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6011 - accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5715 - accuracy: 0.7879\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5515 - accuracy: 0.8030\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4611 - accuracy: 0.8788\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4938 - accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.8485\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8712\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5594 - accuracy: 0.7955\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8636\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4327 - accuracy: 0.8409\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3204 - accuracy: 0.8864\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2542 - accuracy: 0.9318\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3191 - accuracy: 0.9015\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1828 - accuracy: 0.9545\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1946 - accuracy: 0.9394\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1587 - accuracy: 0.9242\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1649 - accuracy: 0.9470\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1470 - accuracy: 0.9545\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1282 - accuracy: 0.9545\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1385 - accuracy: 0.9697\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1278 - accuracy: 0.9621\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0953 - accuracy: 0.9697\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1377 - accuracy: 0.9621\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0674 - accuracy: 0.9848\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.9773\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1224 - accuracy: 0.9545\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0501 - accuracy: 0.9924\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0387 - accuracy: 0.9924\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0654 - accuracy: 0.9773\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0126 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1630 - accuracy: 0.9697\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1553 - accuracy: 0.9621\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0442 - accuracy: 0.9848\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.2196 - accuracy: 0.9394\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1015 - accuracy: 0.9621\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.2428 - accuracy: 0.9015\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1323 - accuracy: 0.9545\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1651 - accuracy: 0.9394\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1105 - accuracy: 0.9470\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0845 - accuracy: 0.9773\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0742 - accuracy: 0.9697\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0527 - accuracy: 0.9773\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0403 - accuracy: 0.9924\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0197 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fb662eb1c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs=100, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7929 - accuracy: 0.8214\n",
      "\n",
      "Test accuracy =  0.8214285969734192\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 370ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'üòÑ'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = np.array([\"I am happy\"])\n",
    "indices = sentences_to_indices(sentence, word_to_index, maxLen)\n",
    "label_to_emoji(np.argmax(model.predict(indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "i adore you ‚ù§Ô∏è\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "i love you ‚ù§Ô∏è\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "funny lol üòÑ\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "lets play with a ball ‚öæ\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "food is ready üç¥\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "not feeling happy üòû\n",
      "1/1 [==============================] - 0s 386us/step\n",
      "definitely feeling happy üòÑ\n"
     ]
    }
   ],
   "source": [
    "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\", \"definitely feeling happy\"])\n",
    "m = X_my_sentences.shape[0]\n",
    "indices = sentences_to_indices(X_my_sentences, word_to_index, maxLen)\n",
    "for i in range(m):\n",
    "    pred = label_to_emoji(np.argmax(model.predict(indices[i].reshape(1, maxLen))))\n",
    "    print(f\"{X_my_sentences[i]} {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(model, \"./SPN_Emojify.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
